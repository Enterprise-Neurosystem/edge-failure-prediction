{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5157c4a-0ff0-4e13-a754-c3c4037d247a",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "When collecting data from online or real-time sources, the dataset is always a bit dirty. There may be missing values, nulls, or just incorrect inputs. \n",
    "\n",
    "Our columns are relatively clean, so we won't show a very expansive set of cleaning tools, but feel free to check out more of our workshops to experiment with other types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d1853-41bf-4ef2-988b-41882a72adec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(cwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50659e4-6228-45fd-a0ea-d5b97702d6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if the a directory exists, if not create it\n",
    "outdir = \"./scratch\"\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ca72c-2a0f-471a-8d73-0606de80e374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates a connection to a database\n",
    "conn = psycopg2.connect(\n",
    "    database=\"predict-db\", user=\"predict-db\", password=\"failureislame\", host=\"localhost\"\n",
    ")\n",
    "\n",
    "GET_ALL_ROWS = \"Select * from waterpump order by timestamp\"\n",
    "\n",
    "try:\n",
    "    with conn:\n",
    "        # Pull our dataset into a pandas dataframe\n",
    "        df = pd.read_sql_query(GET_ALL_ROWS, conn)\n",
    "        df.set_index(\"timestamp\", inplace=True)\n",
    "except (Exception, psycopg2.DatabaseError) as err:\n",
    "    print(err)\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e2c35-b0c2-44b4-b594-3d47e00ef5d1",
   "metadata": {},
   "source": [
    "### Lets make a copy of the dataset, so that if we make a mistake or just want a clean version of the dataset, we don't need to run that cell above again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b945ccf-56d2-449d-863d-6105e959aca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eecad1-f861-4a05-b410-970dce27a28c",
   "metadata": {},
   "source": [
    "### As we said before, we have some nulls in the data. Let's see if any columns are unusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86daaa-ec36-4009-b114-7c958b50ac82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nulls_series = df.isnull().sum()\n",
    "print(nulls_series.sort_values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a2bb829-ea89-424a-8e71-ee408a49743f",
   "metadata": {},
   "source": [
    "### Something looks wrong with sensor_15 data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc816b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sensor_15\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecacecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop it like it's hot\n",
    "df.drop(\"sensor_15\", axis=1, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e126bdf-9d28-4098-80da-813626ac9a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select the number of columns with too many null values\n",
    "number_removed = 3\n",
    "empty_cols = nulls_series.sort_values().tail(number_removed)\n",
    "display(empty_cols)\n",
    "\n",
    "# get the names of the columns in a list\n",
    "bad_col_list = list(empty_cols.keys())\n",
    "\n",
    "# drop the bad columns\n",
    "df.drop(bad_col_list, axis=1, errors=\"ignore\", inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16b813-f983-4e32-8859-9f9172af36d2",
   "metadata": {},
   "source": [
    "### When we ultimately train a model, we'll need to get all of or columns into numbers\n",
    "### If a non-numerical feature has a discrete distribution, we can implement a practice called one-hot-encoding that will assign our values 0 (False) or 1 (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8b924-226a-4571-9f65-d92810ce5e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we have an in-between stage, 'recovering', so we'll label it 0.5\n",
    "\n",
    "# a dictionary can be used to one-to-one map values in a series\n",
    "status_map = {\"NORMAL\": 0, \"BROKEN\": 1, \"RECOVERING\": 0.5}\n",
    "\n",
    "df[\"machine_status\"] = df[\"machine_status\"].map(status_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1267c-6cc1-4f4c-b484-d2d9fcda2a03",
   "metadata": {},
   "source": [
    "### The index of our dataframe, the time, contains strings. Let's give them a smarter type that understands time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ca58a-9176-4ba4-968e-83e2abba516c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980e17b-c723-461e-99dc-d1098297953a",
   "metadata": {},
   "source": [
    "### Now that all of our columns are numerical, we can run some math operations ourselves for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1953f-6587-4d2c-beca-c47f65441d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe().iloc[:, :15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a310aa-02ad-4bf7-a915-6ac291240b03",
   "metadata": {},
   "source": [
    "### Let's check all the means of our sensors. And while we're at it, let's fill in any null values with those means, so we don't change the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36c2c6-47bd-4cc3-8b8a-078f6c0a0e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_averages = df.mean()\n",
    "print(col_averages)\n",
    "df.fillna(value=col_averages, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b745b34f-4b96-4726-9463-9c212eb44f90",
   "metadata": {},
   "source": [
    "### We should be good to go into further analysis, let's save a csv file so our next notebook can access our updated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49961ae0-c6d3-489d-aa4f-e55552ea2a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(outdir + \"/clean-df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
